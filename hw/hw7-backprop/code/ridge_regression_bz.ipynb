{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import setup_problem\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import numpy as np\n",
    "import nodes\n",
    "import graph\n",
    "import plot_utils\n",
    "\n",
    "class RidgeRegression(BaseEstimator, RegressorMixin):\n",
    "    \"\"\" Ridge regression with computation graph \"\"\"\n",
    "    def __init__(self, l2_reg=1, step_size=.005,  max_num_epochs = 5000):\n",
    "        self.max_num_epochs = max_num_epochs\n",
    "        self.step_size = step_size\n",
    "\n",
    "        # Build computation graph\n",
    "        self.x = nodes.ValueNode(node_name=\"x\") # to hold a vector input\n",
    "        self.y = nodes.ValueNode(node_name=\"y\") # to hold a scalar response\n",
    "        self.w = nodes.ValueNode(node_name=\"w\") # to hold the parameter vector\n",
    "        self.b = nodes.ValueNode(node_name=\"b\") # to hold the bias parameter (scalar)\n",
    "        self.prediction = nodes.VectorScalarAffineNode(x=self.x, w=self.w, b=self.b,\n",
    "                                                 node_name=\"prediction\")\n",
    "        \n",
    "        self.objective = nodes.SquaredL2DistanceNode(a=self.prediction, b=self.y,\n",
    "                        node_name=\"square loss\") + \n",
    "                        nodes.L2NormPenaltyNode(l2_reg=self.l2_reg, w=self.w,\n",
    "                                                node_name=\"l2 penalty\")\n",
    "        # Group nodes into types to construct computation graph function\n",
    "        self.inputs = [self.x]\n",
    "        self.outcomes = [self.y]\n",
    "        self.parameters = [self.w, self.b, self.l2_reg]\n",
    "\n",
    "        self.graph = graph.ComputationGraphFunction(self.inputs, self.outcomes,\n",
    "                                                          self.parameters, self.prediction,\n",
    "                                                          self.objective)\n",
    "        # TODO\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_instances, num_ftrs = X.shape\n",
    "        y = y.reshape(-1)\n",
    "\n",
    "        init_parameter_values = {\"w\": np.zeros(num_ftrs), \"b\": np.array(0.0)}\n",
    "        self.graph.set_parameters(init_parameter_values)\n",
    "\n",
    "        for epoch in range(self.max_num_epochs):\n",
    "            shuffle = np.random.permutation(num_instances)\n",
    "            epoch_obj_tot = 0.0\n",
    "            for j in shuffle:\n",
    "                obj, grads = self.graph.get_gradients(input_values = {\"x\": X[j]},\n",
    "                                                    outcome_values = {\"y\": y[j]})\n",
    "                epoch_obj_tot += obj\n",
    "                # Take step in negative gradient direction\n",
    "                steps = {}\n",
    "                for param_name in grads:\n",
    "                    steps[param_name] = -self.step_size * grads[param_name]\n",
    "                    self.graph.increment_parameters(steps)\n",
    "\n",
    "            if epoch % 50 == 0:\n",
    "                train_loss = sum((y - self.predict(X,y)) **2)/num_instances\n",
    "                print(\"Epoch \",epoch,\": Ave objective=\",epoch_obj_tot/num_instances,\" Ave training loss: \",train_loss)\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        try:\n",
    "            getattr(self, \"graph\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "\n",
    "        num_instances = X.shape[0]\n",
    "        preds = np.zeros(num_instances)\n",
    "        for j in range(num_instances):\n",
    "            preds[j] = self.graph.get_prediction(input_values={\"x\":X[j]})\n",
    "\n",
    "        return preds\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    lasso_data_fname = \"lasso_data.pickle\"\n",
    "    x_train, y_train, x_val, y_val, target_fn, coefs_true, featurize = setup_problem.load_problem(lasso_data_fname)\n",
    "\n",
    "    # Generate features\n",
    "    X_train = featurize(x_train)\n",
    "    X_val = featurize(x_val)\n",
    "\n",
    "    pred_fns = []\n",
    "    x = np.sort(np.concatenate([np.arange(0,1,.001), x_train]))\n",
    "    X = featurize(x)\n",
    "\n",
    "    l2reg = 1\n",
    "    estimator = RidgeRegression(l2_reg=l2reg, step_size=0.00005, max_num_epochs=2000)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    name = \"Ridge with L2Reg=\"+str(l2reg)\n",
    "    pred_fns.append({\"name\":name, \"preds\": estimator.predict(X) })\n",
    "\n",
    "\n",
    "    l2reg = 0\n",
    "    estimator = RidgeRegression(l2_reg=l2reg, step_size=0.0005, max_num_epochs=500)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    name = \"Ridge with L2Reg=\"+str(l2reg)\n",
    "    pred_fns.append({\"name\":name, \"preds\": estimator.predict(X) })\n",
    "\n",
    "    # Let's plot prediction functions and compare coefficients for several fits\n",
    "    # and the target function.\n",
    "\n",
    "    pred_fns.append({\"name\": \"Target Parameter Values (i.e. Bayes Optimal)\", \"coefs\": coefs_true, \"preds\": target_fn(x)})\n",
    "\n",
    "    plot_utils.plot_prediction_functions(x, pred_fns, x_train, y_train, legend_loc=\"best\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
